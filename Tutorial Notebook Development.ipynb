{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Notes for me:\n",
    "- Remove always show toolbar before starting\n",
    "- Set zoom to 150%\n",
    "- check there is internet\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Python and Scikit Learn\n",
    "\n",
    "Follow presentation on: http://bit.ly/ML-SpringCampus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "The process of teaching computers to learn from data.\n",
    "\n",
    "### Learning tasks:\n",
    "\n",
    "- Clustering\n",
    "\n",
    "- Regression\n",
    "\n",
    "- Outlier Detection\n",
    "\n",
    "- Classification\n",
    "\n",
    "- Time series prediction\n",
    "- ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised vs Unsupervised Learning\n",
    "\n",
    "<!--## Classification vs Regression-->\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at some code:\n",
    "\n",
    "We will use:\n",
    " - [Pandas: Python Data Analysis Library](http://pandas.pydata.org/)\n",
    " - [Scikit-Learn](http://scikit-learn.org/stable/)\n",
    " - [Numpy](http://www.numpy.org/)\n",
    " - [Matplotlib](matplotlib.org)\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "__Importing stuff...__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import Utils\n",
    "from Utils import cmap_light\n",
    "from Utils import cmap_bold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "# Boston House Prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boston_dataset = datasets.load_boston()\n",
    "print(boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## The data\n",
    "\n",
    "\n",
    "__Dataset:__ \n",
    "\n",
    "a set of __examples__ each characterized by __features__ and  usually there is a __label variable__ that you want to predict. \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## Let's see a real example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = boston_dataset.data\n",
    "Y = boston_dataset.target\n",
    "\n",
    "names = list(boston_dataset.feature_names) + ['Price']\n",
    "\n",
    "labels = np.reshape(Y,\n",
    "                     (Y.shape[0], 1))\n",
    "df = pd.DataFrame(data=np.concatenate((X, labels), axis=1),\n",
    "                 columns=names)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tmp = df[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX',\n",
    "             'RM', 'Price']]\n",
    "df_tmp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tmp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Utils import plot_boston_dataset\n",
    "plot_boston_dataset(boston_dataset.data, \n",
    "                    boston_dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## First model:  Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "<img src=\"https://imgs.xkcd.com/comics/linear_regression.png\" title=\"XKCD: Linear Regression\" width=\"512\" height=\"342\" />\n",
    "\n",
    "_The 95% confidence interval suggests Rexthor's dog could also be a cat, or possibly a teapot._\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X, Y)\n",
    "\n",
    "r2 = model.score(X, Y)\n",
    "\n",
    "print(\"R^2 value: {:0.3f}\".format(r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "# Congratulations!\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_n = np.random.randint(0, Y.shape[0])\n",
    "\n",
    "Utils.describe_example_boston_dataset(X[example_n])\n",
    "\n",
    "print(\"\\n\\nPredicted price: {:2.2f} Real value: {:2.2f}\".format(\n",
    "        model.predict(X[example_n].reshape(1, -1))[0], Y[example_n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## Distinguishing Species of Iris plants:\n",
    "\n",
    "<br><br>\n",
    "<img src=\"https://c1.staticflickr.com/1/402/31713322286_8c85f8b6b6_z.jpg\" title=\"Iris flower\" width=\"512\" height=\"342\" />\n",
    "\n",
    "[Source: Big Cypress National Preserve](https://www.flickr.com/photos/bigcypressnps/31713322286/in/photolist-Qjp4QJ-ha3kMy-4KVwB4-4Minkn-fb7Jye-sb5tXz-dsWnJ9-4LhUuW-6oioBi-4LhUdA-GFsivk-szxsRT-dkse9b-4KVwk4-GPNUCc-dksd7u-ha6uis-dtXQmu-2enBH-qsaLo7-qsaUYy-rp5XxE-rp9N4p-r7JFac-r5SjCe-dksdro-dkscBm-HKf4AB-LcBBEv-dksbkv-dksb2i-dksa8H-dksbDi-rRTCUf-wRiRYq-dksd3N-dkscSd-dkscP5-dksag6-a2hYQC-e26B2-r7AuaS-rp6h47-2enc6-r7CpdL-r7H5uH-r7C435-rmT8D1-r7BefQ-J4WHV)\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "print(\"Features: \" + str(iris_dataset.feature_names))\n",
    "print(\"Classes: \" + str(iris_dataset.target_names))\n",
    "\n",
    "X = iris_dataset.data\n",
    "y = iris_dataset.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load it to a DF\n",
    "idx = np.random.permutation(150)\n",
    "y = y[idx]\n",
    "X = X[idx]\n",
    "\n",
    "labels = np.reshape(y,\n",
    "                    (y.shape[0], 1))\n",
    "df = pd.DataFrame(data=np.concatenate((X, labels), axis=1),\n",
    "                 columns=iris_dataset.feature_names + ['Class'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a peak at the data:\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = \"bry\"\n",
    "for i, color in zip([0, 1, 2], colors):\n",
    "    idx = np.where(y == i)\n",
    "    plt.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired)\n",
    "    \n",
    "plt.text(5.25, 2.20, \"Versicolor\", fontsize=14)\n",
    "plt.text(7, 3.5, \"Virginica\", fontsize=14)\n",
    "plt.text(4.5, 3.75, \"Setosa\", fontsize=14)\n",
    "\n",
    "plt.title(\"The 3 different Iris species\", fontsize=18, \n",
    "          fontweight='bold')    \n",
    "plt.xlabel(iris_dataset.feature_names[0], fontsize=14)\n",
    "plt.ylabel(iris_dataset.feature_names[1], fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will focus identifying only the Iris Setosa\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = \"br\"\n",
    "\n",
    "idx = np.where(y == 0) # Give me the indices of the Iris Setosa examples\n",
    "\n",
    "plt.scatter(X[idx, 0], X[idx, 1], c='b', cmap=plt.cm.Paired)\n",
    "plt.text(4.5, 3.75, \"Setosa\", fontsize=14)\n",
    "\n",
    "idx = np.where(y != 0) # where it's not Iris Setosa \n",
    "plt.scatter(X[idx, 0], X[idx, 1], c='r', cmap=plt.cm.Paired)\n",
    "plt.text(7.0, 2.5, \"Others\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.title(\"Scatter plot of Iris Setosa and the others Iris\",\n",
    "          fontsize=18, fontweight='bold')  \n",
    "plt.xlabel(iris_dataset.feature_names[0], fontsize=14)\n",
    "plt.ylabel(iris_dataset.feature_names[1], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "### Second model  Logistic Regression\n",
    "<br></br>\n",
    "<br></br>\n",
    "<img src=\"2HardProblems.png\" title=\"Tweet\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We only care about whether each flower is a \n",
    "#     Iris Setosa and we are looking only at two of their features\n",
    "\n",
    "X = iris_dataset.data\n",
    "y = iris_dataset.target\n",
    "\n",
    "new_y = y == 0\n",
    "\n",
    "model = LogisticRegression(random_state=42, verbose=0)\n",
    "\n",
    "model.fit(X[:,0:2], new_y)\n",
    "\n",
    "accuracy = model.score(X[:,0:2], new_y)\n",
    "\n",
    "print(\"Accuracy: {:0.3f}%\".format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Utils import predict_mesh\n",
    "\n",
    "# Let's take a look at what our model is doing\n",
    "\n",
    "# First plot the examples\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = \"br\"\n",
    "\n",
    "idx = np.where(y == 0)\n",
    "plt.scatter(X[idx, 0], X[idx, 1], c='b', cmap=plt.cm.Paired)\n",
    "plt.text(4.5, 3.75, \"Setosa\", fontsize=14)\n",
    "\n",
    "idx = np.where(y != 0)\n",
    "plt.scatter(X[idx, 0], X[idx, 1], c='r', cmap=plt.cm.Paired)\n",
    "plt.text(7.0, 2.5, \"Others\", fontsize=14)\n",
    "\n",
    "(xx, yy, Z) = predict_mesh(X, model)\n",
    "plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "\n",
    "plt.title(\"Decision Boundary\", fontsize=18, fontweight='bold')   \n",
    "plt.xlabel(iris_dataset.feature_names[0], fontsize=14)\n",
    "plt.ylabel(iris_dataset.feature_names[1], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## Linear Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how do these models work?\n",
    "\n",
    "Let's start with linear regression:\n",
    "\n",
    "$$ \\hat{y} = w_0 + w_1.x_1 + w_2.x_2 + w_3.x_3$$ \n",
    "\n",
    "Adding a $x_0=1$ we get\n",
    "\n",
    "\n",
    "$$ \\hat{y} = w^T \\cdot x $$\n",
    "\n",
    "For each variable we have a weight, an \"importance\", and the linear combination of the weights and features results in our estimated value $\\hat{y}$.\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "### What about the weights?\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "# Questions?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "### Logistic Regression\n",
    "\n",
    "\n",
    "#### Same model + Classifier function\n",
    "\n",
    "__Model:__\n",
    "\n",
    "$$ \\hat{y} = w^T \\cdot x $$\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "__Model + classification:__\n",
    "\n",
    "\n",
    "$$ \\hat{y} = g(w^T \\cdot x) $$\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "### Sigmoid function\n",
    "\n",
    "$$g(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = np.arange(-20, 20, 0.001)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Sigmoid Function\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Now to a real world example! \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br> \n",
    "# Scotch!\n",
    "<img src=\"https://c1.staticflickr.com/7/6184/6105844311_dc4c31b8b7_b.jpg\" title=\"Scotch whiskies\" width=\"716\" height=\"403\" />\n",
    "\n",
    "[Source: Damien Pollet](https://flic.kr/p/aiy3MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "# First look at the data\n",
    "\n",
    "Data from: [Whisky Classified](https://www.amazon.com/Whisky-Classified-Choosing-Single-Flavour/dp/1862059136) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the data file and drop the collumns we don't care about:\n",
    "whisky_dataframe = pd.read_csv(\n",
    "    filepath_or_buffer=\"whiskies.csv\", header=0, sep=',',\n",
    "    index_col=1)\n",
    "whisky_dataframe.drop(['RowID', 'Postcode', ' Latitude',\n",
    "                       ' Longitude'], inplace=True, axis=1)\n",
    "whisky_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whisky_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Utils.plot_whisky_histograms(whisky_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Utils.plot_whiky_body_correlation(whisky_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "# Let's do a Detour\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## The Curse of Dimentionality\n",
    " \n",
    "__ More features != Better Results __\n",
    "\n",
    " _ When the dimensionality increases, the volume of the space increases so fast that the available data become sparse._\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Utils.plot_1d_random_data(0.5, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Utils.plot_2d_random_data(0.5, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## Feature selection and extraction\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_data_1 =np.random.multivariate_normal(\n",
    "    mean= [0, 0], cov=[[5, 5], [0, 0.5]], size=100)\n",
    "\n",
    "random_data_2 =np.random.multivariate_normal(\n",
    "    mean= [6, 6], cov=[[5, 5], [0, 0.5]], size=100)\n",
    "\n",
    "random_data = np.concatenate([random_data_1, random_data_2], axis=0)\n",
    "random_labels = np.concatenate([np.ones((100,1)),np.zeros((100,1))], axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.scatter(random_data[:, 0], random_data[:, 1], c=random_labels, cmap=cmap_light)\n",
    "#plt.scatter(random_data_2[:, 0], random_data_2[:, 1], c='r')\n",
    "\n",
    "plt.plot([-5, 10], [-5, 10], 'r--')\n",
    "plt.plot([5, 0], [0, 5], 'g--')\n",
    "\n",
    "plt.xlim((-7, 14))\n",
    "plt.ylim((-7, 14))\n",
    "plt.title('Random Data with Principal Components', fontsize=16)\n",
    "\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(random_data)\n",
    "transformed_data = pca.fit_transform(random_data)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(transformed_data[:,0], transformed_data[:,1],\n",
    "            c=random_labels, cmap=cmap_light)\n",
    "plt.plot([-10, 10], [0, 0], 'r--')\n",
    "plt.xlim((-10, 10))\n",
    "plt.ylim((-5, 5))\n",
    "plt.title('Transformed Random Data', fontsize=16)\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "pca.fit(random_data)\n",
    "transformed_data = pca.fit_transform(random_data)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(transformed_data[:,0], np.zeros((200,1)),\n",
    "            c=random_labels, cmap=cmap_light)\n",
    "plt.plot([-10, 10], [0, 0], 'r--')\n",
    "plt.xlim((-10, 10))\n",
    "plt.ylim((-5, 5))\n",
    "plt.title('Transformed Random Data', fontsize=16)\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"% of variance explained by PCA: {:0.1f}% \\\n",
    "        \".format(\n",
    "        pca.explained_variance_ratio_[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## Model complexity and overfitting\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adapted from: http://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html \n",
    "# Author: Mathieu Blondel\n",
    "#         Jake Vanderplas\n",
    "# License: BSD 3 clause\n",
    "\n",
    "def f(x, noise=False):\n",
    "    \"\"\" function to approximate by polynomial interpolation\"\"\"\n",
    "    if(noise):\n",
    "        return np.sin(x) + np.random.randn(x.shape[0])/4\n",
    "    return np.sin(x)\n",
    "\n",
    "space_size = 6\n",
    "\n",
    "# generate points used to plot\n",
    "x_plot = np.linspace(-space_size, space_size, 100)\n",
    "\n",
    "# generate points and keep a subset of them\n",
    "x = np.linspace(-space_size, space_size, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "rng.shuffle(x)\n",
    "x = np.sort(x[:10])\n",
    "y = f(x, True)\n",
    "\n",
    "# create matrix versions of these arrays\n",
    "X = x[:, np.newaxis]\n",
    "X_plot = x_plot[:, np.newaxis]\n",
    "\n",
    "colors = ['teal', 'yellowgreen', 'gold', 'blue']\n",
    "lw = 2\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "    \n",
    "\n",
    "for count, degree in enumerate([1, 3, 6, 10]):\n",
    "    ax = fig.add_subplot(2, 2, count+1)\n",
    "    ax.plot(x_plot, f(x_plot), color='cornflowerblue', linewidth=lw,\n",
    "         label=\"ground truth\")\n",
    "    ax.scatter(x, y, color='navy', s=30, marker='o', label=\"training points\")\n",
    "    model = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "    model.fit(X, y)\n",
    "    y_plot = model.predict(X_plot)\n",
    "    ax.plot(x_plot, y_plot, color=colors[count], linewidth=lw,\n",
    "             label=\"degree %d\" % degree)\n",
    "\n",
    "    ax.legend(loc='lower left')\n",
    "    ax.set_ylim((-5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Back to Scotch!\n",
    "\n",
    "Let's apply what we learned to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whisky_data = whisky_dataframe.values\n",
    "\n",
    "pca = PCA(n_components=2, whiten=True) \n",
    "\n",
    "# Here whiten means centering the data around 0, \n",
    "# which is needed so that PCA works correctly\n",
    "transformed_data = pca.fit_transform(whisky_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"% of variance explained by each component: \\\n",
    "       \\n 1st {:0.1f}% \\\n",
    "       \\n 2nd {:0.1f}% \\\n",
    "        \".format(\n",
    "        pca.explained_variance_ratio_[0]*100, \n",
    "        pca.explained_variance_ratio_[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(x = transformed_data[:,0], y=transformed_data[:,1])\n",
    "\n",
    "plt.xlim((-3, 5))\n",
    "plt.ylim((-3, 5))\n",
    "\n",
    "plt.title('Transformed Whisky Data', fontsize=16)\n",
    "plt.xlabel('Principal Component 1', fontsize=14)\n",
    "plt.ylabel('Principal Component 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "### Predicting whether it has Tobacco taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = whisky_dataframe['Tobacco']\n",
    "whisky_data = whisky_dataframe.drop('Tobacco', axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Percentage of Positive Labels: {:.2f}%\".format(\n",
    "        np.sum(labels)/len(labels)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "### Unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, whiten=True) \n",
    "# Here whiten means centering the data around 0, \n",
    "# which is neededso that PCA works correctly\n",
    "transformed_data = pca.fit_transform(whisky_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    transformed_data, labels, test_size=0.30, random_state=0)\n",
    "\n",
    "# Without Class weights\n",
    "classf = LogisticRegression()\n",
    "\n",
    "# With Class weights\n",
    "class_weight={0:1, 1: 12}\n",
    "classf = LogisticRegression(class_weight=class_weight)\n",
    "\n",
    "classf.fit(train_data, train_labels)\n",
    "\n",
    "accuracy = classf.score(train_data, train_labels)\n",
    "\n",
    "print(\"\\n\\nTraining Accuracy:\\t {:0.3f}%\\n\\n\".format(accuracy*100))\n",
    "\n",
    "accuracy = classf.score(test_data, test_labels)\n",
    "\n",
    "print(\"Test Accuracy:\\t\\t {:0.3f}%\\n\\n\".format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\tTraining \\n\")\n",
    "predicted_labels = classf.predict(train_data)\n",
    "cm = confusion_matrix(train_labels, predicted_labels)\n",
    "Utils.print_cm(cm)\n",
    "\n",
    "print(\"\\n\\tTesting \\n\")\n",
    "\n",
    "predicted_labels = classf.predict(test_data)\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "Utils.print_cm(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## Cross Validation\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg\" alt=\"K-fold cross validation EN.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_weight={0:1, 1: 12}\n",
    "\n",
    "classf = LogisticRegression(random_state=42, \n",
    "                            class_weight=class_weight)\n",
    "#classf = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select parameters to use in Cross-Validation\n",
    "classf_cv = classf\n",
    "data_cv = transformed_data\n",
    "N_CV = 10\n",
    "\n",
    "# Cross Validation\n",
    "t0 = time()\n",
    "scores = cross_val_score(classf_cv, data_cv, labels, cv = N_CV)\n",
    "print(\"Scores: \")\n",
    "for i, score in enumerate(scores):\n",
    "    print( '\\t' + str(i) + ':\\t' + str(score)) \n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"\\nCross val done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## Resources:\n",
    "\n",
    "#### Online Courses:\n",
    "- [Machine Learning by Andrew Ng](https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "#### Books:\n",
    "- [Master Algorithm](https://www.amazon.com/Master-Algorithm-Ultimate-Learning-Machine/dp/0465065708)\n",
    "- [Pattern Recognition and Machine Learning](https://www.amazon.co.uk/Pattern-Recognition-Learning-Information-Statistics-x/dp/0387310738)\n",
    "\n",
    "#### Articles:\n",
    "- [A few useful things to know about Machine Learning](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
    "\n",
    "\n",
    "#### Tutorials:\n",
    "- [Kaggle: Predicting Survival rate on the Titanic](https://www.kaggle.com/c/titanic)\n",
    "- [Scikit-Learn Tutorials](http://scikit-learn.org/stable/tutorial/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br><br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## Unsupervised Learning\n",
    " \n",
    " ### Clustering: K -means\n",
    " \n",
    " TODO: Explain with toy data set, add video / GIF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Scotch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "## Model Complexity and Overfitting\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_data = np.random.randn(100, 2)\n",
    "random_labels = np.random.randint(0,2,100)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.scatter(random_data[:, 0], random_data[:, 1],\n",
    "            c=random_labels, cmap=cmap_bold)\n",
    "\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "clf.fit(random_data, random_labels)\n",
    "\n",
    "print(\"Accuracy: {:0.3f}%\".format(\n",
    "        clf.score(random_data, random_labels)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(xx, yy, Z) = Utils.predict_mesh(random_data, clf, h=0.01)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "plt.scatter(random_data[:, 0], random_data[:, 1],\n",
    "            c=random_labels, cmap=cmap_bold)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_labels = np.concatenate([np.ones((50,)), np.zeros((50,))])\n",
    "\n",
    "random_data = np.concatenate([\n",
    "    np.add(np.multiply(np.random.randn(50, 2), \n",
    "                       np.array([0.7, 1.5])), np.array([3, 1])),\n",
    "    np.multiply(np.random.randn(50, 2), \n",
    "                np.array([0.5, 3]))\n",
    "    ]) \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.scatter(random_data[:, 0], random_data[:, 1], \n",
    "            c=random_labels, cmap=cmap_bold)\n",
    "plt.xlim((-4, 8))\n",
    "plt.ylim((-6, 6))\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is so much more\n",
    "\n",
    "This can not even be considered scraping the surface. Go ahead and experiment it's a very interesting field, and there are tons of information and places to learn from!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whisky_data = pd.read_csv(\n",
    "    filepath_or_buffer=\"Meta-Critic Whisky Database â€“ Selfbuilts Whisky Analysis.csv\")\n",
    "whisky_data.describe()\n",
    "whisky_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLTutorial",
   "language": "python",
   "name": "mltutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
