{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Python and Scikit Learn\n",
    "\n",
    "Follow presentation on: http://bit.ly/ML-SpringCampus\n",
    "\n",
    "\n",
    "Notes for me:\n",
    "- Remove always show toolbar before starting\n",
    "- Set zoom to 150%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "The process of teaching computers to learn from data.\n",
    "\n",
    "### Learning tasks:\n",
    "\n",
    "- Clustering\n",
    "\n",
    "- Regression\n",
    "\n",
    "- Outlier Detection\n",
    "\n",
    "- Classification\n",
    "\n",
    "- Time series prediction\n",
    "\n",
    "### The data\n",
    "\n",
    "A dataset is a set of examples used to train a Machine Learning model\n",
    "\n",
    "An example contains information about an object or event;\n",
    "\n",
    "The example is represented by its features.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised vs Unsupervised Learning\n",
    "\n",
    "\n",
    "\n",
    "## Supervised:\n",
    "\n",
    "#### Classification vs Regression\n",
    "\n",
    "__Classifier__: Predictor with a categorical\n",
    "\n",
    "__Regressor__: Predictor with a continuous output\n",
    "\n",
    "\n",
    "\n",
    "Imagine you a program to help you trade stocks and make money from it. There are two possible ways of facing this problem, you can make a problem to predict the price of the stock each day or you can make a program that just tells you whether you shoul __buy__, __sell__ or __do nothing__ each day.\n",
    "\n",
    "## Unsupervised Learning\n",
    "\n",
    "Unsupervised Learning is to try to learn something from data, but without having any labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised\n",
    "## Let's look at some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_mesh(X, clf, gap=0.3, h=0.01):\n",
    "    x_min, x_max = X[:, 0].min() - gap, X[:, 0].max() + gap\n",
    "    y_min, y_max = X[:, 1].min() - gap, X[:, 1].max() + gap\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    return (xx, yy, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguishing Species of Iris plants:\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<img src=\"https://c1.staticflickr.com/1/402/31713322286_8c85f8b6b6_z.jpg\" title=\"Iris flower\" width=\"640\" height=\"427\" />\n",
    "\n",
    "[Source: Big Cypress National Preserve](https://www.flickr.com/photos/bigcypressnps/31713322286/in/photolist-Qjp4QJ-ha3kMy-4KVwB4-4Minkn-fb7Jye-sb5tXz-dsWnJ9-4LhUuW-6oioBi-4LhUdA-GFsivk-szxsRT-dkse9b-4KVwk4-GPNUCc-dksd7u-ha6uis-dtXQmu-2enBH-qsaLo7-qsaUYy-rp5XxE-rp9N4p-r7JFac-r5SjCe-dksdro-dkscBm-HKf4AB-LcBBEv-dksbkv-dksb2i-dksa8H-dksbDi-rRTCUf-wRiRYq-dksd3N-dkscSd-dkscP5-dksag6-a2hYQC-e26B2-r7AuaS-rp6h47-2enc6-r7CpdL-r7H5uH-r7C435-rmT8D1-r7BefQ-J4WHV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "print(\"Features: \" + str(iris_dataset.feature_names))\n",
    "print(\"Classes: \" + str(iris_dataset.target_names))\n",
    "\n",
    "X = iris_dataset.data\n",
    "y = iris_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a peak at the data:\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = \"bry\"\n",
    "for i, color in zip([0, 1, 2], colors):\n",
    "    idx = np.where(y == i)\n",
    "    plt.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired)\n",
    "    \n",
    "plt.text(5.25, 2.20, \"Versicolor\", fontsize=14)\n",
    "plt.text(7, 3.5, \"Virginica\", fontsize=14)\n",
    "plt.text(4.5, 3.75, \"Setosa\", fontsize=14)\n",
    "\n",
    "plt.title(\"The 3 different Iris species\", fontsize=18, fontweight='bold')        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will focus identifying only the Iris Setosa\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = \"br\"\n",
    "\n",
    "idx = np.where(y == 0) # Give me the indices of the Iris Setosa examples\n",
    "\n",
    "plt.scatter(X[idx, 0], X[idx, 1], c='b', cmap=plt.cm.Paired)\n",
    "plt.text(4.5, 3.75, \"Setosa\", fontsize=14)\n",
    "\n",
    "idx = np.where(y != 0) # where it's not Iris Setosa \n",
    "plt.scatter(X[idx, 0], X[idx, 1], c='r', cmap=plt.cm.Paired)\n",
    "plt.text(7.0, 2.5, \"Others\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.title(\"Scatter plot of Iris Setosa and the others Iris\", fontsize=18, fontweight='bold')        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "Looking at this plot, if I have a new flower that would be at (4.5, 4.0)  what kind of Iris would you predict it is? \n",
    "and here (7.0, 3.5)?\n",
    "and here (7.0, 4.0)? \n",
    "\n",
    "That's exactly what a machine learning algorithm does it uses the available data to make predictions, some times it get's it right other times it fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first model  Logistic Regression\n",
    "\n",
    "First let's see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We only care about whether each flower is a Iris Setosa \n",
    "new_y = y==0\n",
    "\n",
    "\n",
    "model = LogisticRegression(random_state=42, verbose=0).fit(X[:,0:2], new_y)\n",
    "print(\"Accuracy: {:0.3f}%\".format(model.score(X[:,0:2], new_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at what our model is doing\n",
    "\n",
    "# First plot the examples\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = \"br\"\n",
    "\n",
    "idx = np.where(y == 0)\n",
    "plt.scatter(X[idx, 0], X[idx, 1], c='b', cmap=plt.cm.Paired)\n",
    "plt.text(4.5, 3.75, \"Setosa\", fontsize=14)\n",
    "\n",
    "idx = np.where(y != 0)\n",
    "plt.scatter(X[idx, 0], X[idx, 1], c='r', cmap=plt.cm.Paired)\n",
    "plt.text(7.0, 2.5, \"Others\", fontsize=14)\n",
    "\n",
    "(xx, yy, Z) = predict_mesh(X, model)\n",
    "plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "\n",
    "#plt.title(\"Iris Setosa vs the others\", fontsize=18, fontweight='bold')        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second model  Linear Regression \n",
    "\n",
    "Who has heard of it? who has used it? maybe with Excel?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston_dataset = datasets.load_boston()\n",
    "print(boston_dataset.DESCR)\n",
    "\n",
    "X = boston_dataset.data\n",
    "Y = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the data\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax1 = fig.add_subplot(2,3,1)\n",
    "ax2 = fig.add_subplot(2,3,2)\n",
    "ax3 = fig.add_subplot(2,3,3)\n",
    "ax4 = fig.add_subplot(2,3,4)\n",
    "ax5 = fig.add_subplot(2,3,5)\n",
    "ax6 = fig.add_subplot(2,3,6)\n",
    "\n",
    "ax1.scatter(x = X[:,0], y=Y, alpha= 0.3)\n",
    "ax1.set_xlabel('per capita crime')\n",
    "ax1.set_ylabel('Median value')\n",
    "\n",
    "\n",
    "ax2.scatter(x = X[:,4], y=Y, alpha= 0.3)\n",
    "ax2.set_xlabel('nitric oxides concentration')\n",
    "ax2.set_ylabel('Median value')\n",
    "\n",
    "ax3.scatter(x = X[:,5], y=Y, alpha= 0.3)\n",
    "ax3.set_xlabel('average number of rooms ')\n",
    "ax3.set_ylabel('Median value')\n",
    "\n",
    "\n",
    "ax4.scatter(x = X[:,9], y=Y, alpha= 0.3)\n",
    "ax4.set_xlabel('full-value property-tax')\n",
    "ax4.set_ylabel('Median value')\n",
    "\n",
    "\n",
    "ax5.scatter(x = X[:,6], y=Y, alpha= 0.3)\n",
    "ax5.set_xlabel('AGE')\n",
    "ax5.set_ylabel('Median value')\n",
    "\n",
    "\n",
    "ax6.scatter(x = X[:,12], y=Y, alpha= 0.3)\n",
    "ax6.set_xlabel('LSTAT')\n",
    "ax6.set_ylabel('Median value')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X, Y)\n",
    "print(\"R^2 value: {:0.3f}\".format(model.score(X, Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in an higher dimention, we can't easily visualize this model, so we have to rely on metrics to estimate the model's performance. \n",
    "\n",
    "We can also look at some examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def describe_example_boston_dataset(example):\n",
    "    if(example.shape != (13,)):\n",
    "        print(\"Unable to describe\")\n",
    "        return\n",
    "    for i in range(0, 13):\n",
    "        print(\"Feature: {:8s} - {:8.2f}\".format(boston_dataset.feature_names[i], example[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_n = np.random.randint(0, Y.shape[0])\n",
    "\n",
    "describe_example_boston_dataset(X[example_n])\n",
    "\n",
    "print(\"\\n\\nPredicted price: {:2.2f} Real value: {:2.2f}\".format(model.predict(X[example_n].reshape(1, -1))[0],\n",
    "                                                            Y[example_n]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how do these models work?\n",
    "\n",
    "Let's start with linear regression:\n",
    "\n",
    "$$ \\hat{y} = w_0 + w_1.x_1 + w_2.x_2 + w_3.x_3$$ \n",
    "\n",
    "Adding a $x_0=1$ we get\n",
    "\n",
    "\n",
    "$$ \\hat{y} = w^T \\cdot x $$\n",
    "\n",
    "For each variable we have a weight, an \"importance\", and the linear combination of the weights and features results in our estimated value $\\hat{y}$.\n",
    "\n",
    "Questions?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we find the weights?\n",
    "\n",
    "It's an optimization problem we want to find the weights that minimize the error over all the examples we have for training.\n",
    "\n",
    "We can use any kind of optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We want to use the same linear model  but now build a classifier.\n",
    "\n",
    "\n",
    "For that we use the Logistic/Signmoid function .\n",
    "\n",
    "taking:\n",
    "\n",
    "$$ \\hat{y} = w^T \\cdot x $$\n",
    "\n",
    "\n",
    "$$ \\hat{y} = g(w^T \\cdot x) $$\n",
    "\n",
    "where: \n",
    "\n",
    "$$g(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = np.arange(-20, 20, 0.001)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Sigmoid Function\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to a real world example! \n",
    "\n",
    "Let's take the knowledge we gained and try to apply it to a real world dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "# Scotch!\n",
    "![Scotch whiskies](https://c1.staticflickr.com/7/6184/6105844311_dc4c31b8b7_b.jpg)\n",
    "[Source: Damien Pollet](https://flic.kr/p/aiy3MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First look at the data\n",
    "\n",
    "We will use [Pandas: Python Data Analysis Library](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the data file and drop the collumns we don't care about:\n",
    "whisky_dataframe = pd.read_csv(filepath_or_buffer=\"whiskies.csv\", header=0, sep=',', index_col=1)\n",
    "whisky_dataframe.drop(['RowID', 'Postcode', ' Latitude', ' Longitude'], inplace=True, axis=1)\n",
    "whisky_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whisky_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "ax1 = fig.add_subplot(3,4,1)\n",
    "ax2 = fig.add_subplot(3,4,2)\n",
    "ax3 = fig.add_subplot(3,4,3)\n",
    "ax4 = fig.add_subplot(3,4,4)\n",
    "ax5 = fig.add_subplot(3,4,5)\n",
    "ax6 = fig.add_subplot(3,4,6)\n",
    "ax7 = fig.add_subplot(3,4,7)\n",
    "ax8 = fig.add_subplot(3,4,8)\n",
    "ax9 = fig.add_subplot(3,4,9)\n",
    "ax10 = fig.add_subplot(3,4,10)\n",
    "ax11 = fig.add_subplot(3,4,11)\n",
    "ax12 = fig.add_subplot(3,4,12)\n",
    "\n",
    "ax1.hist(x=whisky_dataframe['Smoky'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax1.set_title(\"Smoky\", fontsize=15)\n",
    "ax1.set_xticks([0,1,2,3,4,5])\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "ax2.hist(x=whisky_dataframe['Honey'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax2.set_title(\"Honey\", fontsize=15)\n",
    "ax2.set_xticks([0,1,2,3,4])\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "ax3.hist(x=whisky_dataframe['Body'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax3.set_title(\"Body\", fontsize=15)\n",
    "ax3.set_xticks([0,1,2,3,4])\n",
    "ax3.set_ylabel('Frequency')\n",
    "\n",
    "ax4.hist(x=whisky_dataframe['Nutty'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax4.set_title(\"Nutty\", fontsize=15)\n",
    "ax4.set_xticks([0,1,2,3,4])\n",
    "ax4.set_ylabel('Frequency')\n",
    "\n",
    "ax5.hist(x=whisky_dataframe['Malty'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax5.set_title(\"Malty\", fontsize=15)\n",
    "ax5.set_xticks([0,1,2,3,4])\n",
    "ax5.set_ylabel('Frequency')\n",
    "\n",
    "ax6.hist(x=whisky_dataframe['Fruity'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax6.set_title(\"Smoky\", fontsize=15)\n",
    "ax6.set_xticks([0,1,2,3,4])\n",
    "ax6.set_ylabel('Frequency')\n",
    "\n",
    "ax7.hist(x=whisky_dataframe['Sweetness'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax7.set_title(\"Sweetness\", fontsize=15)\n",
    "ax7.set_xticks([0,1,2,3,4])\n",
    "ax7.set_ylabel('Frequency')\n",
    "\n",
    "ax8.hist(x=whisky_dataframe['Medicinal'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax8.set_title(\"Medicinal\", fontsize=15)\n",
    "ax8.set_xticks([0,1,2,3,4])\n",
    "ax8.set_ylabel('Frequency')\n",
    "\n",
    "ax9.hist(x=whisky_dataframe['Tobacco'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax9.set_title(\"Tobacco\", fontsize=15)\n",
    "ax9.set_xticks([0,1,2,3,4])\n",
    "ax9.set_ylabel('Frequency')\n",
    "\n",
    "ax10.hist(x=whisky_dataframe['Spicy'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax10.set_title(\"Spicy\", fontsize=15)\n",
    "ax10.set_xticks([0,1,2,3,4])\n",
    "ax10.set_ylabel('Frequency')\n",
    "\n",
    "ax11.hist(x=whisky_dataframe['Winey'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax11.set_title(\"Winey\", fontsize=15)\n",
    "ax11.set_xticks([0,1,2,3,4])\n",
    "ax11.set_ylabel('Frequency')\n",
    "\n",
    "ax12.hist(x=whisky_dataframe['Floral'], bins=range(0,5), rwidth=0.85, align='right')\n",
    "ax12.set_title(\"Floral\", fontsize=15)\n",
    "ax12.set_xticks([0,1,2,3,4])\n",
    "ax12.set_ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax1 = fig.add_subplot(3,3,1)\n",
    "ax2 = fig.add_subplot(3,3,2)\n",
    "ax3 = fig.add_subplot(3,3,3)\n",
    "ax4 = fig.add_subplot(3,3,4)\n",
    "ax5 = fig.add_subplot(3,3,5)\n",
    "ax6 = fig.add_subplot(3,3,6)\n",
    "ax7 = fig.add_subplot(3,3,7)\n",
    "ax8 = fig.add_subplot(3,3,8)\n",
    "ax9 = fig.add_subplot(3,3,9)\n",
    "\n",
    "ax1.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Sweetness'], alpha=0.1, s=500)\n",
    "ax1.set_xticks([0, 1, 2, 3, 4])\n",
    "ax1.set_yticks([0, 1, 2, 3, 4])\n",
    "ax1.set_xlabel('Body')\n",
    "ax1.set_ylabel('Sweetness')\n",
    "\n",
    "ax2.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Smoky'], alpha=0.1, s=500)\n",
    "ax2.set_xticks([0, 1, 2, 3, 4])\n",
    "ax2.set_yticks([0, 1, 2, 3, 4])\n",
    "ax2.set_xlabel('Body')\n",
    "ax2.set_ylabel('Smoky')\n",
    "\n",
    "ax3.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Medicinal'], alpha=0.1, s=500)\n",
    "ax3.set_xticks([0, 1, 2, 3, 4])\n",
    "ax3.set_yticks([0, 1, 2, 3, 4])\n",
    "ax3.set_xlabel('Body')\n",
    "ax3.set_ylabel('Medicinal')\n",
    "\n",
    "ax4.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Tobacco'], alpha=0.1, s=500)\n",
    "ax4.set_xticks([0, 1, 2, 3, 4])\n",
    "ax4.set_yticks([0, 1, 2, 3, 4])\n",
    "ax4.set_xlabel('Body')\n",
    "ax4.set_ylabel('Tobacco')\n",
    "\n",
    "ax5.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Floral'], alpha=0.1, s=500)\n",
    "ax5.set_xticks([0, 1, 2, 3, 4])\n",
    "ax5.set_yticks([0, 1, 2, 3, 4])\n",
    "ax5.set_xlabel('Body')\n",
    "ax5.set_ylabel('Floral')\n",
    "\n",
    "ax6.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Fruity'], alpha=0.1, s=500)\n",
    "ax6.set_xticks([0, 1, 2, 3, 4])\n",
    "ax6.set_yticks([0, 1, 2, 3, 4])\n",
    "ax6.set_xlabel('Body')\n",
    "ax6.set_ylabel('Fruity')\n",
    "\n",
    "ax7.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Nutty'], alpha=0.1, s=500)\n",
    "ax7.set_xticks([0, 1, 2, 3, 4])\n",
    "ax7.set_yticks([0, 1, 2, 3, 4])\n",
    "ax7.set_xlabel('Body')\n",
    "ax7.set_ylabel('Nutty')\n",
    "\n",
    "ax8.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Malty'], alpha=0.1, s=500)\n",
    "ax8.set_xticks([0, 1, 2, 3, 4])\n",
    "ax8.set_yticks([0, 1, 2, 3, 4])\n",
    "ax8.set_xlabel('Body')\n",
    "ax8.set_ylabel('Malty')\n",
    "\n",
    "ax9.scatter(x = whisky_dataframe['Body'], y=whisky_dataframe['Winey'], alpha=0.1, s=500)\n",
    "ax9.set_xticks([0, 1, 2, 3, 4])\n",
    "ax9.set_yticks([0, 1, 2, 3, 4])\n",
    "ax9.set_xlabel('Body')\n",
    "ax9.set_ylabel('Winey')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whisky_data = whisky_dataframe.values\n",
    "whisky_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "### The more data you have the better? Not always:\n",
    "\n",
    "__ The curse of dimentionality__\n",
    " \n",
    " \n",
    " _ When the dimensionality increases, the volume of the space increases so fast that the available data become sparse. _\n",
    " \n",
    " \n",
    "__ Model Complexity__\n",
    "\n",
    "#### Feature selection and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_data = np.random.randn(100, 2)\n",
    "random_labels = np.random.randint(0,2,100)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.scatter(random_data[:, 0], random_data[:, 1], c=random_labels, cmap=cmap_bold)\n",
    "\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(random_data, random_labels)\n",
    "\n",
    "print(\"Accuracy: {:0.3f}%\".format(clf.score(random_data, random_labels)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(xx, yy, Z) = predict_mesh(random_data, clf, h=0.01)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "plt.scatter(random_data[:, 0], random_data[:, 1], c=random_labels, cmap=cmap_bold)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The curse of Dimensionality\n",
    "\n",
    "__ More features != Better Results __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_labels = np.concatenate([np.ones((50,)), np.zeros((50,))])\n",
    "\n",
    "random_data = np.concatenate([\n",
    "    np.add(np.multiply(np.random.randn(50, 2), np.array([0.7, 1.5])), np.array([3, 1])),\n",
    "    np.multiply(np.random.randn(50, 2), np.array([0.5, 3]))\n",
    "    ]) \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.scatter(random_data[:, 0], random_data[:, 1], c=random_labels, cmap=cmap_bold)\n",
    "plt.xlim((-4, 8))\n",
    "plt.ylim((-6, 6))\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "Principal componentes are the directions of largest variance\n",
    "\n",
    "The eigenvectors with the largest eigenvalues are the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_data =np.random.multivariate_normal(mean= [0, 0], cov=[[5, 5], [0, 0.5]], size=100)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.scatter(random_data[:, 0], random_data[:, 1])\n",
    "plt.plot([-5, 5], [-5, 5], 'r--')\n",
    "plt.plot([1.5, -1.5], [-1.5, 1.5], 'g--')\n",
    "\n",
    "plt.xlim((-7, 7))\n",
    "plt.ylim((-7, 7))\n",
    "plt.title('Random Data with Principal Components', fontsize=16)\n",
    "\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(random_data)\n",
    "transformed_data = pca.fit_transform(random_data)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(transformed_data[:,0], transformed_data[:,1])\n",
    "plt.plot([-5, 5], [0, 0], 'r--')\n",
    "plt.xlim((-7, 7))\n",
    "plt.ylim((-7, 7))\n",
    "plt.title('Transformed Random Data', fontsize=16)\n",
    "plt.xlabel('Random Dimension 1', fontsize=14)\n",
    "plt.ylabel('Random Dimension 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Scotch!\n",
    "\n",
    "Let's apply what we learned to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, whiten=True) \n",
    "# Here whiten means centering the data around 0, which is needed so that PCA works correctly\n",
    "transformed_data = pca.fit_transform(whisky_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"% of variance explained by each component: 1st {:0.1f}% 2nd {:0.1f}%\".format(\n",
    "        pca.explained_variance_ratio_[0]*100, pca.explained_variance_ratio_[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(x = transformed_data[:,0], y=transformed_data[:,1])\n",
    "\n",
    "plt.xlim((-3, 5))\n",
    "plt.ylim((-3, 5))\n",
    "\n",
    "plt.title('Transformed Whisky Data', fontsize=16)\n",
    "plt.xlabel('Principal Component 1', fontsize=14)\n",
    "plt.ylabel('Principal Component 2', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Try PCA with 3 components? and plot them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting whether it has Tobacco taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = whisky_dataframe['Tobacco']\n",
    "whisky_data = whisky_dataframe.drop('Tobacco', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Percentage of Positive Labels: {:.2f}%\".format(np.sum(labels)/len(labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight={0:1, 1: 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, whiten=True) \n",
    "# Here whiten means centering the data around 0, which is needed so that PCA works correctly\n",
    "transformed_data = pca.fit_transform(whisky_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classf = LogisticRegression(random_state=42, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select parameters to use in Cross-Validation\n",
    "classf_cv = classf\n",
    "data_cv = transformed_data\n",
    "N_CV = 10\n",
    "\n",
    "# Cross Validation\n",
    "t0 = time()\n",
    "scores = cross_validation.cross_val_score(classf_cv, data_cv, labels, cv = N_CV)\n",
    "print(\"Scores: \")\n",
    "for i, score in enumerate(scores):\n",
    "    print( '\\t' + str(i) + ':\\t' + str(score)) \n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"\\nCross val done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    transformed_data, labels, test_size=0.20)\n",
    "\n",
    "classf = LogisticRegression(class_weight=class_weight)\n",
    "\n",
    "classf.fit(train_data, train_labels)\n",
    "\n",
    "predicted_labels = classf.predict(test_data)\n",
    "confusion_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Unsupervised Learning\n",
    " \n",
    " ### Clustering: K -means\n",
    " \n",
    " TODO: Explain with toy data set, add video / GIF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Scotch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's make some predictions: (Tobacco ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How evaluate our models? \n",
    "#### Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is so much more\n",
    "\n",
    "This can not even be considered scraping the surface. Go ahead and experiment it's a very interesting field, and there are tons of information and places to learn from!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whisky_data = pd.read_csv(filepath_or_buffer=\"Meta-Critic Whisky Database â€“ Selfbuilts Whisky Analysis.csv\")\n",
    "whisky_data.describe()\n",
    "whisky_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLTutorial",
   "language": "python",
   "name": "mltutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
